---
name: scrape and deploy
on:
  push:
    paths-ignore:
      - 'README.md'
      - 'LICENSE'
jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      max-parallel: 4
      matrix:
        feed:
          - zapping

    steps:
      - uses: actions/checkout@v2

      - name: Set up Python 3
        uses: actions/setup-python@v1
        with:
          python-version: '~3.8'

      - name: Get pip cache directory
        id: pip-cache-dir
        run: |
          python -c "from pip._internal.locations import USER_CACHE_DIR; print('::set-output name=dir::' + USER_CACHE_DIR)"

      - name: Cache pip
        uses: actions/cache@v1
        with:
          path: ${{ steps.pip-cache-dir.outputs.dir }}
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Scrape
        run: >-
          python3 -m scrapy crawl ${{ matrix.feed }}
          -o 'emptyfile://${{ github.workspace }}/dist/${{ matrix.feed }}.rss'
          -t ${{ matrix.feed }} --loglevel=INFO

      - uses: jakejarvis/s3-sync-action@v0.5.1
        env:
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          # optional: defaults to us-east-1
          AWS_REGION: ${{ secrets.AWS_REGION }}
          # optional: defaults to entire repository
          SOURCE_DIR: ${{ github.workspace }}/dist
        with:
          args: --delete --content-type application/rss+xml
...
